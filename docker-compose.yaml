x-base-config: &base-config
  restart: always
  deploy:
    resources:
      limits:
        memory: 1G
      reservations:
        memory: 512M
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

services:
  nginx:
    container_name: nginx
    image: nginx:latest
    volumes:
      - ./nginx_config/nginx.conf:/etc/nginx/nginx.conf:ro
      # - ./certbot/conf:/etc/letsencrypt:ro
      # - ./certbot/www:/var/www/certbot:ro
    depends_on:
      - vllm
      - litellm
    ports:
      - 80:80
        #- 443:443
    networks:
      - vllm-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  vllm:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm
    ipc: host
    ports:
      #   - "8000:8000" # 8000 IS UNUSED
      - "9009:9009"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    env_file:
      - .env
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HF_TOKEN}
      TORCH_CUDA_ARCH_LIST: 7.5
      VLLM_USE_V1: 0
    command: --model Qwen/Qwen3-1.7B --served-model-name qwen3-1.7b --enforce-eager --max-model-len 3k --host 0.0.0.0 --port 9009 --swap-space 0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - vllm-network

  litellm:
    container_name: litellm
    image: ghcr.io/berriai/litellm:v1.75.5-stable
    ports:
      - "8001:4000"
    volumes:
      - ./litellm_config/litellm_config.yaml:/app/config.yaml # Mount the local configuration file
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    env_file:
      - .env
    environment:
      LITELLM_MASTER_KEY: $LITELLM_MASTER_KEY
      NO_DOCS: ${LITELLM_NO_DOCS:-true}
      UI_USERNAME: $LITELLM_UI_USERNAME
      UI_PASSWORD: $LITELLM_UI_KEY
      DATABASE_URL: "postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgredb:5432/${LITELLM_POSTGRES_DB:-litellm}"
    <<: *base-config
    depends_on:
      - vllm
      - postgredb
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    networks:
      - vllm-network

  vllm_logger:
    container_name: vllm_logger
    build:
      context: ./vllm_logger
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env
    <<: *base-config
    depends_on:
      - postgredb
    networks:
      - vllm-network

  postgredb:
    image: pgvector/pgvector:pg16
    container_name: postgredb
    # environment:
    #   - DB_HOST=localhost
    env_file:
      - .env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      # - ./postgres_config/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: always
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 3s
      timeout: 3s
      retries: 10
    deploy:
      resources:
        limits:
          memory: 3g
        reservations:
          memory: 2g
    networks:
      - vllm-network
    <<: *base-config

  minio:
    image: minio/minio:latest
    container_name: mlflow-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-f",
          "http://localhost:${MINIO_PORT}/minio/health/live",
        ]
      interval: 5s
      timeout: 3s
      retries: 20

  create-bucket:
    image: minio/mc:latest
    container_name: mlflow-create-bucket
    depends_on:
      minio:
        condition: service_healthy
    entrypoint:
      - /bin/sh
      - -c
      - |
        mc alias set myminio "http://${MINIO_HOST}:${MINIO_PORT}" \
          "${MINIO_ROOT_USER}" "${MINIO_ROOT_PASSWORD}"
        mc mb --ignore-existing "myminio/${MINIO_BUCKET:-mlflow}"
    restart: "no"

  mlflow:
    image: ghcr.io/mlflow/mlflow:${MLFLOW_VERSION}
    container_name: mlflow-server
    depends_on:
      postgredb:
        condition: service_healthy
      minio:
        condition: service_healthy
      create-bucket:
        condition: service_completed_successfully
    environment:
      # Backend store URI built from vars
      MLFLOW_BACKEND_STORE_URI: ${MLFLOW_BACKEND_STORE_URI}

      # S3/MinIO settings
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      MLFLOW_ARTIFACTS_DESTINATION: ${MLFLOW_ARTIFACTS_DESTINATION}
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      MLFLOW_S3_IGNORE_TLS: "true"

      # Server host/port
      MLFLOW_HOST: ${MLFLOW_HOST}
      MLFLOW_PORT: ${MLFLOW_PORT}

    command:
      - /bin/bash
      - -c
      - |
        pip install --no-cache-dir psycopg2-binary boto3
        mlflow server \
          --backend-store-uri "${MLFLOW_BACKEND_STORE_URI}" \
          --artifacts-destination "${MLFLOW_ARTIFACTS_DESTINATION}" \
          --host "${MLFLOW_HOST}" \
          --port "${MLFLOW_PORT}"
    ports:
      - "${MLFLOW_PORT}:${MLFLOW_PORT}"
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:${MLFLOW_PORT}/health')",
        ]
      interval: 10s
      timeout: 5s
      retries: 30

networks:
  vllm-network:
    driver: bridge

volumes:
  postgres-data:
    driver: local
  langfuse_clickhouse_data:
    driver: local
  langfuse_clickhouse_logs:
    driver: local
  langfuse_minio_data:
    driver: local
